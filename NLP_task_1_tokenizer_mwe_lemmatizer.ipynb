{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import tokenizer\n",
    "from spacy.lang.en import English\n",
    "from  spacy.matcher import Matcher, PhraseMatcher\n",
    "import spacy\n",
    "import re\n",
    "import cupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#source of en_core_web_sm is from OntoNotes 5\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "#source of en_core_web_md is from  OntoNotes 5 and GloVe Common Crawl \n",
    "nlp_large = spacy.load('en_core_web_md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "doc = nlp(\"\"\"Modern natural language processing\n",
    "(NLP) research requires writing code.\n",
    "Ideally this code would provide a precise definition of the approach, easy\n",
    "repeatability of results, and a basis for\n",
    "extending the research. However, many\n",
    "research codebases bury high-level parameters under implementation details,\n",
    "are challenging to run and debug, and are\n",
    "difficult enough to extend that they are\n",
    "more likely to be rewritten. This paper\n",
    "describes AllenNLP, a library for applying\n",
    "deep learning methods to NLP research,\n",
    "which addresses these issues with easy-to-use command-line tools, declarative\n",
    "configuration-driven experiments, and\n",
    "modular NLP abstractions. AllenNLP\n",
    "has already increased the rate of research\n",
    "experimentation and the sharing of NLP\n",
    "components at the Allen Institute for\n",
    "Artificial Intelligence, and we are working\n",
    "to have the same impact across the field.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red\">Tokenizing</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_1 = nlp(\"Modern natural language processing (NLP) research requires writing code. Ideally this code would provide a precise definition of the approach, easy repeatability of results, and a basis for extending the research. However, many research codebases bury high-level parameters under implementation details, are challenging to run and debug, and are difficult enough to extend that they are more likely to be rewritten. This paper describes AllenNLP, a library for applying deep learning methods to NLP research, which addresses these issues with easy-to-use command-line tools, declarative configuration-driven experiments, and modular NLP abstractions. AllenNLP has already increased the rate of research experimentation and the sharing of NLP components at the Allen Institute for Artificial Intelligence, and we are working to have the same impact across the field.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Modern,\n",
       " natural,\n",
       " language,\n",
       " processing,\n",
       " (,\n",
       " NLP,\n",
       " ),\n",
       " research,\n",
       " requires,\n",
       " writing,\n",
       " code,\n",
       " .,\n",
       " Ideally,\n",
       " this,\n",
       " code,\n",
       " would,\n",
       " provide,\n",
       " a,\n",
       " precise,\n",
       " definition,\n",
       " of,\n",
       " the,\n",
       " approach,\n",
       " ,,\n",
       " easy,\n",
       " repeatability,\n",
       " of,\n",
       " results,\n",
       " ,,\n",
       " and,\n",
       " a,\n",
       " basis,\n",
       " for,\n",
       " extending,\n",
       " the,\n",
       " research,\n",
       " .,\n",
       " However,\n",
       " ,,\n",
       " many,\n",
       " research,\n",
       " codebases,\n",
       " bury,\n",
       " high,\n",
       " -,\n",
       " level,\n",
       " parameters,\n",
       " under,\n",
       " implementation,\n",
       " details,\n",
       " ,,\n",
       " are,\n",
       " challenging,\n",
       " to,\n",
       " run,\n",
       " and,\n",
       " debug,\n",
       " ,,\n",
       " and,\n",
       " are,\n",
       " difficult,\n",
       " enough,\n",
       " to,\n",
       " extend,\n",
       " that,\n",
       " they,\n",
       " are,\n",
       " more,\n",
       " likely,\n",
       " to,\n",
       " be,\n",
       " rewritten,\n",
       " .,\n",
       " This,\n",
       " paper,\n",
       " describes,\n",
       " AllenNLP,\n",
       " ,,\n",
       " a,\n",
       " library,\n",
       " for,\n",
       " applying,\n",
       " deep,\n",
       " learning,\n",
       " methods,\n",
       " to,\n",
       " NLP,\n",
       " research,\n",
       " ,,\n",
       " which,\n",
       " addresses,\n",
       " these,\n",
       " issues,\n",
       " with,\n",
       " easy,\n",
       " -,\n",
       " to,\n",
       " -,\n",
       " use,\n",
       " command,\n",
       " -,\n",
       " line,\n",
       " tools,\n",
       " ,,\n",
       " declarative,\n",
       " configuration,\n",
       " -,\n",
       " driven,\n",
       " experiments,\n",
       " ,,\n",
       " and,\n",
       " modular,\n",
       " NLP,\n",
       " abstractions,\n",
       " .,\n",
       " AllenNLP,\n",
       " has,\n",
       " already,\n",
       " increased,\n",
       " the,\n",
       " rate,\n",
       " of,\n",
       " research,\n",
       " experimentation,\n",
       " and,\n",
       " the,\n",
       " sharing,\n",
       " of,\n",
       " NLP,\n",
       " components,\n",
       " at,\n",
       " the,\n",
       " Allen,\n",
       " Institute,\n",
       " for,\n",
       " Artificial,\n",
       " Intelligence,\n",
       " ,,\n",
       " and,\n",
       " we,\n",
       " are,\n",
       " working,\n",
       " to,\n",
       " have,\n",
       " the,\n",
       " same,\n",
       " impact,\n",
       " across,\n",
       " the,\n",
       " field,\n",
       " .]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tokens for tokens in doc_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Modern natural language processing (NLP) research requires writing code.,\n",
       " Ideally this code would provide a precise definition of the approach, easy repeatability of results, and a basis for extending the research.,\n",
       " However, many research codebases bury high-level parameters under implementation details, are challenging to run and debug, and are difficult enough to extend that they are more likely to be rewritten.,\n",
       " This paper describes AllenNLP, a library for applying deep learning methods to NLP research, which addresses these issues with easy-to-use command-line tools, declarative configuration-driven experiments, and modular NLP abstractions.,\n",
       " AllenNLP has already increased the rate of research experimentation and the sharing of NLP components at the Allen Institute for Artificial Intelligence, and we are working to have the same impact across the field.]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sentences for sentences in doc_1.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Modern natural language processing (NLP) research,\n",
       " code,\n",
       " this code,\n",
       " a precise definition,\n",
       " the approach,\n",
       " easy repeatability,\n",
       " results,\n",
       " a basis,\n",
       " the research,\n",
       " many research codebases,\n",
       " high-level parameters,\n",
       " implementation details,\n",
       " they,\n",
       " This paper,\n",
       " AllenNLP,\n",
       " a library,\n",
       " deep learning methods,\n",
       " NLP research,\n",
       " these issues,\n",
       " easy-to-use command-line tools,\n",
       " declarative configuration-driven experiments,\n",
       " modular NLP abstractions,\n",
       " AllenNLP,\n",
       " the rate,\n",
       " research experimentation,\n",
       " the sharing,\n",
       " NLP components,\n",
       " the Allen Institute,\n",
       " Artificial Intelligence,\n",
       " we,\n",
       " the same impact,\n",
       " the field]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in doc_1.noun_chunks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red\">Multi Word Expression</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi word expression example 1\n",
    "pattern_1 = [{'LOWER':'natural'},{'LOWER':'language'},{'LOWER':'processing'}]\n",
    "patter_2 = [{'LOWER':'artificial'},{'LOWER':'intelligence'}]\n",
    "matcher_1 = Matcher(nlp.vocab)\n",
    "matcher_1.add('nlp_long',None,pattern_1)\n",
    "matcher_1.add('AI',None,patter_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "natural language processing =>start of expression 1.th word and end of expression is 4.th word\n",
      "Artificial Intelligence =>start of expression 135.th word and end of expression is 137.th word\n"
     ]
    }
   ],
   "source": [
    "for matcher_id, start, end in matcher_1(doc_1):\n",
    "    print(doc_1[start:end],'=>start of expression {}.th word and end of expression is {}.th word'.format(start,end))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multi word expression example 2\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "matcher.add('nlp_long',None,nlp('Modern natural language processing'))\n",
    "matcher.add('AI',None,nlp('Artificial Intelligence'))\n",
    "matcher.add('eu_clt',None,nlp('easy-to-use command-line tools'))\n",
    "matcher.add('dev_conf_exp',None,nlp('declarative configuration-driven experiments'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modern natural language processing\n",
      "easy-to-use command-line tools\n",
      "declarative configuration-driven experiments\n",
      "Artificial Intelligence\n"
     ]
    }
   ],
   "source": [
    "for matcher_id, start, end in matcher(doc_1):\n",
    "    print(doc_1[start:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red\">Lemmatizer</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "requires\trequire\n",
      "writing\twrite\n",
      "would\twould\n",
      "provide\tprovide\n",
      "extending\textend\n",
      "bury\tbury\n",
      "challenging\tchallenge\n",
      "run\trun\n",
      "extend\textend\n",
      "rewritten\trewrite\n",
      "describes\tdescribe\n",
      "applying\tapply\n",
      "addresses\taddress\n",
      "use\tuse\n",
      "driven\tdrive\n",
      "increased\tincrease\n",
      "working\twork\n"
     ]
    }
   ],
   "source": [
    "for tokens in doc_1:\n",
    "    if tokens.pos_ =='VERB':\n",
    "        print('{}\\t{}'.format(tokens,tokens.lemma_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#GPU üzerinde çalıştırma\n",
    "spacy.prefer_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
